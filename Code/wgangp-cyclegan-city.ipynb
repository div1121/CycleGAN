{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "@inproceedings{CycleGAN2017,\n",
    "  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},\n",
    "  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},\n",
    "  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},\n",
    "  year={2017}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses, train_zebras = [], []\n",
    "test_horses, test_zebras = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnimagetonumpyA(d,array):\n",
    "    # load the image and convert into\n",
    "    # numpy array\n",
    "    expre = d + '/*_A.jpg'\n",
    "    jpgFilenamesList = glob.glob(expre)\n",
    "    jpgFilenamesList = sorted(jpgFilenamesList)\n",
    "    for name in jpgFilenamesList[:2000]:\n",
    "        img = Image.open(name)\n",
    "        # asarray() class is used to convert\n",
    "        # PIL images into NumPy arrays\n",
    "        numpydata = asarray(img)\n",
    "        #  shape\n",
    "        # print(numpydata.shape)\n",
    "        numpydata = (numpydata / 127.5) - 1\n",
    "        array.append(numpydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnimagetonumpyB(d,array):\n",
    "    # load the image and convert into\n",
    "    # numpy array\n",
    "    expre = d + '/*_B.jpg'\n",
    "    # print(expre)\n",
    "    jpgFilenamesList = glob.glob(expre)\n",
    "    jpgFilenamesList = sorted(jpgFilenamesList)\n",
    "    #print(jpgFilenamesList)\n",
    "    for name in jpgFilenamesList[:2000]:\n",
    "        img = Image.open(name)\n",
    "        # asarray() class is used to convert\n",
    "        # PIL images into NumPy arrays\n",
    "        numpydata = asarray(img)\n",
    "        #  shape\n",
    "        # print(numpydata.shape)\n",
    "        numpydata = (numpydata / 127.5) - 1\n",
    "        array.append(numpydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnimagetonumpyA(\"../input/cityscapedata/dataset/datasets/cityscapes/trainA\",train_horses)      \n",
    "turnimagetonumpyB(\"../input/cityscapedata/dataset/datasets/cityscapes/trainB\",train_zebras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnimagetonumpyA(\"../input/cityscapedata/dataset/datasets/cityscapes/testA\",test_horses)\n",
    "turnimagetonumpyB(\"../input/cityscapedata/dataset/datasets/cityscapes/testB\",test_zebras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapearray(a):\n",
    "    a = numpy.array(a)\n",
    "    a = a.reshape([-1,1,256,256,3])\n",
    "    print(a.shape)\n",
    "    # a = tf.convert_to_tensor(a, dtype=tf.float32)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses = reshapearray(train_horses)\n",
    "train_zebras = reshapearray(train_zebras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_horses = reshapearray(test_horses)\n",
    "test_zebras = reshapearray(test_zebras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Horse')\n",
    "plt.imshow(train_horses[0][0] * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Zebra')\n",
    "plt.imshow(train_zebras[0][0] * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions to be used for discrimiator\n",
    "# This should be (fake_loss - real_loss)\n",
    "# We will add the gradient penalty later to this loss function\n",
    "def discriminator_loss(real, fake):\n",
    "    real_loss = tf.math.reduce_mean(real)\n",
    "    fake_loss = tf.math.reduce_mean(fake)\n",
    "    return fake_loss - real_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions to be used for generator\n",
    "def generator_loss(fake,X_BackB,X_realB,X_BackA,X_realA):\n",
    "    return -tf.math.reduce_mean(fake) + (10 * (tf.math.reduce_mean(tf.math.abs(X_BackB - X_realB)) + tf.math.reduce_mean(tf.math.abs(X_BackA - X_realA))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Flatten()(patch_out)\n",
    "    patch_out = Dense(1)(patch_out)\n",
    "    # define model\n",
    "    model = Model(in_image, patch_out)\n",
    "    # compile model\n",
    "    # model.compile(loss=wasserstein_loss, optimizer=RMSprop(lr=0.00005))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image shape\n",
    "image_shape = (IMG_HEIGHT,IMG_WIDTH,3)\n",
    "# create the model\n",
    "model = define_discriminator(image_shape)\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator a resnet block\n",
    "def resnet_block(n_features, input_layer):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # first layer convolutional layer\n",
    "    g = Conv2D(n_features, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # second convolutional layer\n",
    "    g = Conv2D(n_features, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    # concatenate merge channel-wise with input layer\n",
    "    g = g + input_layer\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,3), n_resnet=6):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # c7s1-64\n",
    "    g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d128\n",
    "    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d256\n",
    "    g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # R256\n",
    "    for _ in range(n_resnet):\n",
    "        g = resnet_block(256, g)\n",
    "    # u128\n",
    "    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # u64\n",
    "    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # c7s1-3\n",
    "    g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_generator()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape\n",
    "image_shape = (256,256,3)\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "# c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "# c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model_A,\n",
    "        d_model_B,\n",
    "        g_model_AtoB,\n",
    "        g_model_BtoA,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.d_model_A = d_model_A\n",
    "        self.d_model_B = d_model_B\n",
    "        self.g_model_AtoB = g_model_AtoB\n",
    "        self.g_model_BtoA = g_model_BtoA\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, da_optimizer, db_optimizer, ga_optimizer, gb_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.da_optimizer = da_optimizer\n",
    "        self.db_optimizer = db_optimizer\n",
    "        self.ga_optimizer = ga_optimizer\n",
    "        self.gb_optimizer = gb_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty_A(self, batch_size, real, fake):\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake - real\n",
    "        interpolated = real + alpha * diff\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = self.d_model_A(interpolated, training=True)\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        norm = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.math.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train(self, b_size=1, n_epoch=20, total=1000, n_batch=1, n_patch=1):\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = b_size\n",
    "        bat_per_epo = total\n",
    "        n_steps = bat_per_epo * n_epoch\n",
    "        \n",
    "        trainA, trainB = train_horses, train_zebras\n",
    "        \n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add gradient penalty to the discriminator loss\n",
    "        # 6. Return generator and discriminator losses as a loss dictionary.\n",
    "\n",
    "        for j in range(n_steps): \n",
    "            for i in range(self.d_steps):\n",
    "                # select a batch of real samples\n",
    "                X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "                X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "                # generate a batch of fake samples\n",
    "                # X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "                # X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "                # update fakes from pool\n",
    "                # X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "                # X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    X_fakeA = self.g_model_BtoA(X_realB, training=True)\n",
    "                    real_logits = self.d_model_A(X_realA, training=True)\n",
    "                    fake_logits = self.d_model_A(X_fakeA, training=True)\n",
    "\n",
    "                    # Calculate discriminator loss using fake and real logits\n",
    "                    d_cost = self.d_loss_fn(real=real_logits, fake=fake_logits)\n",
    "                    # Calculate the gradient penalty\n",
    "                    gp = self.gradient_penalty_A(n_batch, X_realA, X_fakeA)\n",
    "                    # Add the gradient penalty to the original discriminator loss\n",
    "                    d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "                # Get the gradients w.r.t the discriminator loss\n",
    "                d_gradient = tape.gradient(d_loss, self.d_model_A.trainable_variables)\n",
    "                # Update the weights of the discriminator using the discriminator optimizer\n",
    "                self.da_optimizer.apply_gradients(\n",
    "                  zip(d_gradient, self.d_model_A.trainable_variables)\n",
    "                )\n",
    "                \n",
    "            X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "            X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "            with tf.GradientTape() as tape:\n",
    "                X_fakeA = self.g_model_BtoA(X_realB, training=True)\n",
    "                fake_logits = self.d_model_A(X_fakeA, training=True)\n",
    "                X_BackB = self.g_model_AtoB(X_fakeA, training=False)\n",
    "                X_fakeB = self.g_model_AtoB(X_realA, training=False)\n",
    "                X_BackA = self.g_model_BtoA(X_fakeB, training=True)\n",
    "                g_loss = self.g_loss_fn(fake_logits,X_BackB,X_realB,X_BackA,X_realA)\n",
    "                \n",
    "            # Get the gradients w.r.t the generator loss\n",
    "            gen_gradient = tape.gradient(g_loss, self.g_model_BtoA.trainable_variables)\n",
    "            # Update the weights of the generator using the generator optimizer\n",
    "            self.gb_optimizer.apply_gradients(\n",
    "                zip(gen_gradient, self.g_model_BtoA.trainable_variables)\n",
    "            )\n",
    "            \n",
    "            for i in range(self.d_steps):\n",
    "                # select a batch of real samples\n",
    "                X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "                X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "                # generate a batch of fake samples\n",
    "                # X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "                # X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "                # update fakes from pool\n",
    "                # X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "                # X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    X_fakeB = self.g_model_AtoB(X_realA, training=True)\n",
    "                    real_logits = self.d_model_B(X_realB, training=True)\n",
    "                    fake_logits = self.d_model_B(X_fakeB, training=True)\n",
    "\n",
    "                    # Calculate discriminator loss using fake and real logits\n",
    "                    d_cost = self.d_loss_fn(real=real_logits, fake=fake_logits)\n",
    "                    # Calculate the gradient penalty\n",
    "                    gp = self.gradient_penalty_A(n_batch, X_realB, X_fakeB)\n",
    "                    # Add the gradient penalty to the original discriminator loss\n",
    "                    d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "                # Get the gradients w.r.t the discriminator loss\n",
    "                d_gradient = tape.gradient(d_loss, self.d_model_B.trainable_variables)\n",
    "                # Update the weights of the discriminator using the discriminator optimizer\n",
    "                self.db_optimizer.apply_gradients(\n",
    "                  zip(d_gradient, self.d_model_B.trainable_variables)\n",
    "                )\n",
    "                \n",
    "            X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "            X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "            with tf.GradientTape() as tape:\n",
    "                X_fakeB = self.g_model_AtoB(X_realA, training=True)\n",
    "                fake_logits = self.d_model_B(X_fakeB, training=True)\n",
    "                X_BackA = self.g_model_BtoA(X_fakeB, training=False)\n",
    "                X_fakeA = self.g_model_BtoA(X_realB, training=False)\n",
    "                X_BackB = self.g_model_AtoB(X_fakeA, training=True)\n",
    "                g_loss = self.g_loss_fn(fake_logits,X_BackB,X_realB,X_BackA,X_realA)\n",
    "                \n",
    "            # Get the gradients w.r.t the generator loss\n",
    "            gen_gradient = tape.gradient(g_loss, self.g_model_AtoB.trainable_variables)\n",
    "            # Update the weights of the generator using the generator optimizer\n",
    "            self.ga_optimizer.apply_gradients(\n",
    "                zip(gen_gradient, self.g_model_AtoB.trainable_variables)\n",
    "            )\n",
    "            \n",
    "            d_hist.append(float(d_loss.numpy()))\n",
    "            g_hist.append(float(g_loss.numpy()))\n",
    "            # plot_history(d_hist,g_hist,j+1) \n",
    "            if (j+1) % 500 == 0:\n",
    "                ckpt_save_path = ckpt_manager.save()\n",
    "                print(\"d_loss: %f , g_loss: %f\" %(d_loss, g_loss))\n",
    "                save_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hist, g_hist = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"derror.txt\", \"r\") as fp:  \n",
    "    d_hist = json.load(fp)\n",
    "with open(\"gerror.txt\", \"r\") as fp:  \n",
    "    g_hist = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_error():\n",
    "    with open(\"derror.txt\", \"w\") as fp:  \n",
    "        json.dump(d_hist, fp)\n",
    "    with open(\"gerror.txt\", \"w\") as fp:  \n",
    "        json.dump(g_hist, fp)\n",
    "    plt.plot(d_hist, label='crit')\n",
    "    plt.plot(g_hist, label='gen')\n",
    "    plt.legend()\n",
    "    name = '/content/gdrive/My Drive/WGAN/plot_line_plot_loss.png'\n",
    "    plt.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # choose random instances\n",
    "    ix = random.randint(0, dataset.shape[0]-1)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = -numpy.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(dataset)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = numpy.ones((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/kaggle/input/cityscapedata/results (3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_optimizer = Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "gb_optimizer = Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "da_optimizer = Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "db_optimizer = Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(\n",
    "        d_model_A = d_model_A,\n",
    "        d_model_B = d_model_B,\n",
    "        g_model_AtoB = g_model_AtoB,\n",
    "        g_model_BtoA = g_model_BtoA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.compile(\n",
    "        da_optimizer = da_optimizer,\n",
    "        db_optimizer = db_optimizer,\n",
    "        ga_optimizer = ga_optimizer,\n",
    "        gb_optimizer = gb_optimizer,\n",
    "        d_loss_fn = discriminator_loss,\n",
    "        g_loss_fn = generator_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"pretained\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(wgan)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_save_path = ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_hist)\n",
    "print(g_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model.predict(test_input)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X_realA, _ = generate_real_samples(train_zebras, 1, 16)\n",
    "    generate_images(g_model_BtoA, X_realA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X_realA, _ = generate_real_samples(train_horses, 1, 16)\n",
    "    generate_images(g_model_AtoB, X_realA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X_realA, _ = generate_real_samples(test_zebras, 1, 16)\n",
    "    generate_images(g_model_BtoA, X_realA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X_realA, _ = generate_real_samples(test_horses, 1, 16)\n",
    "    generate_images(g_model_AtoB, X_realA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_horses\n",
    "temp = temp.reshape([-1,256,256,3])\n",
    "ans = g_model_AtoB.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realans = test_zebras.reshape([-1,256,256,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tans = (ans + 1) * 127.5\n",
    "trealans = (realans + 1) * 127.5\n",
    "# print(ans)\n",
    "# print(realans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tans = numpy.around(tans).astype(numpy.uint8)\n",
    "trealans = numpy.around(trealans).astype(numpy.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = numpy.zeros((19, 3), dtype=numpy.uint8)\n",
    "colormap[0] = [128, 64, 128]\n",
    "colormap[1] = [244, 35, 232]\n",
    "colormap[2] = [70, 70, 70]\n",
    "colormap[3] = [102, 102, 156]\n",
    "colormap[4] = [190, 153, 153]\n",
    "colormap[5] = [153, 153, 153]\n",
    "colormap[6] = [250, 170, 30]\n",
    "colormap[7] = [220, 220, 0]\n",
    "colormap[8] = [107, 142, 35]\n",
    "colormap[9] = [152, 251, 152]\n",
    "colormap[10] = [70, 130, 180]\n",
    "colormap[11] = [220, 20, 60]\n",
    "colormap[12] = [255, 0, 0]\n",
    "colormap[13] = [0, 0, 142]\n",
    "colormap[14] = [0, 0, 70]\n",
    "colormap[15] = [0, 60, 100]\n",
    "colormap[16] = [0, 80, 100]\n",
    "colormap[17] = [0, 0, 230]\n",
    "colormap[18] = [119, 11, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findclosestindex(colormap,temp):\n",
    "    value = 255 * 3\n",
    "    temp = numpy.tile(temp,(19,1))\n",
    "    dif = colormap - temp\n",
    "    dif = numpy.absolute(dif)\n",
    "    t = dif.sum(axis=1)\n",
    "    result = numpy.where(t == numpy.amin(t))\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colortomap(t,colormap):\n",
    "    answer = []\n",
    "    e = t.reshape([-1,3])\n",
    "    for x in e:\n",
    "        value = findclosestindex(colormap,x)\n",
    "        answer.append(value)\n",
    "    return numpy.array(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tans = colortomap(tans,colormap)\n",
    "tans = tans.reshape([500,256,256])\n",
    "print(tans.shape)\n",
    "trealans = colortomap(trealans,colormap)\n",
    "trealans = trealans.reshape([500,256,256])\n",
    "print(trealans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test,answer):\n",
    "    mean_class = []\n",
    "    total = answer.size\n",
    "    matches = test == answer\n",
    "    print(matches.shape)\n",
    "    print(matches.sum(),total)\n",
    "    for x in range(19):\n",
    "        x = numpy.repeat(x,total)\n",
    "        x = x.reshape(-1,256,256)\n",
    "        ematches = x == answer\n",
    "        class_sum = matches.sum()\n",
    "        testmatch = x == test\n",
    "        testmatch = numpy.logical_and(testmatch, ematches)\n",
    "        mean_class.append(testmatch.sum() / class_sum)\n",
    "    return matches.sum() / total , mean_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_acc, class_acc = evaluate(tans,trealans)\n",
    "print(pixel_acc)\n",
    "print(class_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
